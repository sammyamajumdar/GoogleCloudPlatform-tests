{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7dqBknisuQ3fVNeFeDzPb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DocExtractor GCP:\n",
        "\n",
        "1. Upload file to GCS (ideally through a front-end dashboard).\n",
        "2. Grab the file through API and send it to DocAI processor (Output format JSON).\n",
        "3. Upload JSON output to BigQuery table.\n",
        "\n",
        "Front-End: \n",
        "1. Create dashboard (possibly with React bootstrap)\n"
      ],
      "metadata": {
        "id": "WtKzS97vr1Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os\n",
        "from google.cloud import storage\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import documentai_v1 as documentai\n",
        "from google.api_core.exceptions import FailedPrecondition"
      ],
      "metadata": {
        "id": "f7EseUMWuOi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set path to private key file in local machine (json)\n",
        "# create service account credentials and grab json key file \n",
        "PATH_TO_KEY_JSON = '/' \n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = PATH_TO_KEY_JSON # setting environment variable to the json key file"
      ],
      "metadata": {
        "id": "FsfjgNRevnbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.api_core import client_options\n",
        "# helper functions\n",
        "\n",
        "## Create Google Cloud Storage Bucket\n",
        "storage_client = storage.Client()\n",
        "def create_bucket(BUCKET_NAME):\n",
        "    bucket = storage_client.bucket(BUCKET_NAME)\n",
        "    # standard frequency access class\n",
        "    bucket.storage_class = 'Standard'\n",
        "    # location 'EU'\n",
        "    bucket.location = 'EU'\n",
        "    # create bucket\n",
        "    bucket = storage_client.create_bucket(bucket)\n",
        "    # print details of buckets as a dict\n",
        "    print(vars(bucket))\n",
        "\n",
        "## Upload files to GCS\n",
        "def upload_file_to_bucket(blob_name, file_path, BUCKET_NAME):\n",
        "    try:\n",
        "        # Grabs an existing bucket\n",
        "        bucket = storage_client.get_bucket(BUCKET_NAME)\n",
        "        # upload to bucket as a binary large object (blob)\n",
        "        blob = bucket.blob(blob_name)\n",
        "        blob.upload_from_filename(file_path) \n",
        "        return True\n",
        "    except Exception as e:\n",
        "        # print error if upload fails\n",
        "        print(e)\n",
        "        return False\n",
        "\n",
        "## Create specialised processor in docAI\n",
        "def create_processor(project_id, location, processor_name, processor_type):\n",
        "    # setting the api endpoint\n",
        "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
        "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
        "\n",
        "    # allocating processor to project ID and location\n",
        "    parent = client.common_location_path(project_id, location)\n",
        "    processor = client.create_processor(parent=parent,\n",
        "                                        processor=documentai.Processor(\n",
        "                                            display_name=processor_name,\n",
        "                                            type_=processor_type\n",
        "                                        ))\n",
        "    print(f\"Processor Name: {processor.name}\")\n",
        "    print(f\"Processor Display Name: {processor.display_name}\")\n",
        "    print(f\"Processor Type: {processor.type_}\")\n",
        "\n",
        "## Enable processor\n",
        "def enable_processor(project_id, location, processor_id):\n",
        "    # setting the api end point to EU\n",
        "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
        "\n",
        "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
        "    processor_name = client.processor_path(project_id, location, processor_id)\n",
        "    request = documentai.EnableProcessorRequest(name=processor_name)\n",
        "\n",
        "    try:\n",
        "        # make processor request\n",
        "        operation = client.enable_processor(request=request) ## client.disable_processor / client.delete_processosr\n",
        "        print(operation.operation.name)\n",
        "        operation.result()\n",
        "    except FailedPrecondition as e:\n",
        "        # throws error if processor is already activated\n",
        "        print(e.message)\n",
        "\n",
        "## Send processing request\n",
        "# this function is specific to Optical Character Recognition (OCR) processor\n",
        "# additional functions and/or logic required to provision specialised processors based on document type eg passports, driving licences, forms or contracts \n",
        "\n",
        "def send_proc_req(project_id, location, processor_id, file_path, mime_type):\n",
        "    # set api endpoint to EU\n",
        "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
        "\n",
        "    # Allocate to processor\n",
        "    resource_name = client.processor_path(project_id, location, processor_id)\n",
        "\n",
        "    # read file to memory\n",
        "    with open(FILE_PATH, 'rb') as image:\n",
        "    image_content = image.read()\n",
        "\n",
        "    # payload message of raw document content (bytes).\n",
        "    raw_doc = documentai.RawDocument(content=image_content, mime_type=MIME_TYPE)\n",
        "    request = documentai.ProcessRequest(name=RESOURCE_NAME, raw_document=raw_doc)\n",
        "\n",
        "    result = docai_client.process_document(request=request)\n",
        "\n",
        "    document_object = result.document\n",
        "    print('Document proc complete')\n",
        "    print(f\"Text: {document_object.text}\")\n",
        "    "
      ],
      "metadata": {
        "id": "SkqOjqX9vWP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional functions required: \n",
        "\n",
        "1. functions for provisioning different processor type\n",
        "2. function to dynamically determind type of document (could be user provided.)\n",
        "3. Disable processor after completion of processing\n",
        "4. function to create a bigQuery table\n",
        "5. function to upload JSON output to BigQuery table\n",
        "6. further analytics"
      ],
      "metadata": {
        "id": "-i15UQijE0uz"
      }
    }
  ]
}